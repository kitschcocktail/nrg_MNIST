# -*- coding: utf-8 -*-
"""
Created on Mon Aug 10 11:19:08 2015

@author: heiligenstein
"""

#!/usr/bin/env python
import time

try:
    import PIL.Image as Image
except ImportError:
    import Image

import numpy
import random
import theano
import theano.tensor as T
import os
import cPickle
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix



from theano.tensor.shared_randomstreams import RandomStreams

os.chdir("output_folder")

# load RBM parameters
f = cPickle.load(open('DBN.pkl','rb'))
W0     = f[0][0].get_value(borrow=True)
hbias0 = f[0][1].get_value(borrow=True)
vbias0 = f[0][2].get_value(borrow=True)

W1     = f[1][0].get_value(borrow=True)
hbias1 = f[1][1].get_value(borrow=True)
vbias1 = f[1][2].get_value(borrow=True)

W2     = f[2][0].get_value(borrow=True)
hbias2 = f[2][1].get_value(borrow=True)
vbias2 = f[2][2].get_value(borrow=True)
U      = f[2][3].get_value(borrow=True)
dbias  = f[2][4].get_value(borrow=True)

os.chdir("..")    

from logistic_sgd import load_data            
dataset = 'mnist.pkl.gz'
datasets = load_data(dataset)
test_set_x, test_set_y = datasets[2]

# show iamge
#plt.imshow(-three.reshape(28,28), cmap=cm.gray)
zero    = test_set_x.get_value(borrow=True)[346]
one    = test_set_x.get_value(borrow=True)[2]
two    = test_set_x.get_value(borrow=True)[9874]
five    = test_set_x.get_value(borrow=True)[2987]
nine    = test_set_x.get_value(borrow=True)[9]

def classify_MNIST(digit_image, imp_pc=None):
    """
    This script return a 10 column image of MNIST digits generated by our DBN. 
    Between samples the top-level associative memory is run for numCDiters of
    alternating Gibbs sampling between samples.
    The generative model is: lab <--> top <--> pen --> hid --> vis
    With dimensions        : 10  <--> 2000 <--> 500 --> 500 --> 784
    
    :param digit : number of the digit you want to generate 
    :digit type: int
    :param numCDiter: iterations of alternating Gibbs sampling between samples
    :param type: int
    """
    
    
    def ran_1(input_array, pc):
        """Imputes randomly scattered 1s."""
        x = int(len(input_array) * (float(pc) / 100))
        node = random.sample(xrange(0, len(input_array)), x)
        impo = numpy.array(input_array)
        for i in node:
            impo[i] = 1
        return impo
   

    def sigmoid(z):
        return  1 / (1 + numpy.exp(-z))
    
    def energy_vh(vlayer, vbias, hlayer, hbias, W):
        ''' Function to compute the energy of joint configuration (v, h)'''
        # e = -sumVisibleBias - sumHiddenBias - sumVisibleWeightHidden
        sum_vb = numpy.dot(vlayer, vbias)
        #print sum_vb
        sum_hb = numpy.dot(hlayer, hbias)
        #print sum_hb
        vWh = numpy.dot(numpy.dot(vlayer, W), hlayer)
        #print vWh
        E = -sum_vb - sum_hb - vWh
        return E    
    

        
    def fe_v(vlayer, vbias, hbias, W): # works
        ''' Function to compute free energy of visible vector v'''
        # f_e = -sumVisibleBias - sumLog(1 + exp(sumVisibleWeight + hbias))
        sum_vb = numpy.dot(vlayer, vbias)
        vW = (numpy.dot(vlayer, W)) + hbias
        sumLog = sum(numpy.log(1 + numpy.exp(vW))) 
        # numpy.log(1 + numpy.exp(numpy.dot(layer1statessmall,
        #                       numpy.transpose(Wsmall)[0]) + hbias1small[0]))
        F = -sum_vb - sumLog
        return F
        
    def fe_v4(vlayer, vbias, hbias, W):
         hlayerprobs = sigmoid(numpy.dot(vlayer,W) + hbias)
         vW = numpy.dot(vlayer, W)
         vWhp = numpy.dot(vW, hlayerprobs)
         sum_vb = numpy.dot(vlayer, vbias)
         sum_hhp = numpy.dot(hbias, hlayerprobs)
         H = sum((hlayerprobs*numpy.log(hlayerprobs)) + 
            ((1 - hlayerprobs)*numpy.log(1 - hlayerprobs)))
         F4 = -vWhp - sum_vb - sum_hhp + H
         return F4
    
    if imp_pc:
        digit_image = ran_1(digit_image, imp_pc)
        

    # Perform a bottom-up pass to get wake/positive phase probabilites 
    # and sample states

    wakehidprobs   = sigmoid(numpy.dot(digit_image,W0) + hbias0)
    wakehidstates  = (wakehidprobs > numpy.random.rand(1, 500)).astype(float)[0]
    #e0             = energy_vh(digit_image, vbias0, wakehidstates, hbias0, W0)
    fe0            = fe_v(digit_image, vbias0, hbias0, W0)
    wakepenprobs   = sigmoid(numpy.dot(wakehidstates,W1) + hbias1)
    wakepenstates  = (wakepenprobs > numpy.random.rand(1, 500)).astype(float)[0]
    #e1             = energy_vh(wakehidstates, vbias1, wakepenstates, hbias1, W1)
    fe1            = fe_v(wakehidstates, vbias1, hbias1, W1)
    waketopprobs   = sigmoid(numpy.dot(wakepenstates,W2) + hbias2)
    waketopstates  = (waketopprobs > numpy.random.rand(1,2000)).astype(float)[0]
    #e2             = energy_vh(wakepenstates, vbias2, waketopstates, hbias2, W2)
    fe2            = fe_v(wakepenstates, vbias2, hbias2, W2)

    #clayerprobs = sigmoid(numpy.dot(waketopstates,U.T) + dbias)
    #pyh = numpy.exp(dbias + numpy.dot(waketopstates_noU, U.T)) / sum(numpy.exp(dbias + numpy.dot(waketopstates_noU, U.T)))
    #pyh2 = sigmoid(numpy.dot())
    #clayerstates = (clayerprobs > numpy.random.rand(1,10)).astype(float)
    #E = energy_xyh(data, vbias0, wakehidstates[0], hbias0, waketopstates, dbias, W0, U)
    clayerstates = (numpy.dot(waketopstates, U.T) + dbias) / 100
    #e_class = energy_vh(clayerstates, dbias, waketopstates, hbias2, U)
    fe_class = fe_v(clayerstates, dbias, hbias2, U)
    classified_as = numpy.where(clayerstates == numpy.amax(clayerstates))
    #E = e0 + e1 + e2 + e_class
    FE = fe0 + fe1 + fe2 + fe_class

    return classified_as[0][0], FE

os.chdir(os.getcwd() + "/test_results")

pos = 1
fig = plt.figure(figsize=(8,20))
Es = []
FEs = []
for pc in range(0, 10):
    wrong = 0
    Es_pc = []
    FEs_pc = []
    pred_ys = []
    true_ys = []
    for i in range(1000):
        image = test_set_x.get_value(borrow=True)[i]
        pred_y, E, FE = classify_MNIST(image, imp_pc=pc)
        true_y = test_set_y.eval()[i]
        Es_pc.append(E)
        FEs_pc.append(FE)
        pred_ys.append(pred_y)
        true_ys.append(true_y)
        if pred_y != true_y:
            wrong += 1
    pc_wrong = float(wrong) / 10
    Es.append(Es_pc)
    FEs.append(FEs_pc)
    cm = confusion_matrix(true_ys, pred_ys)
    ax = fig.add_subplot(5, 2, pos)
    plt.imshow(cm, interpolation="none")
    title = str(pc) + '% imputation'
    plt.title(title)
    xlabel = str(pc_wrong) + '% wrong' + \
            ' mean E:' + str(int(numpy.mean(Es_pc))) + \
            ' mean FE:' + str(int(numpy.mean(FEs_pc)))
    plt.xlabel(xlabel)
    #print 'average E:', numpy.mean(Es), 'average FE:', numpy.mean(FEs)
    pos += 1
plt.tight_layout()
fig.savefig('confusion_matrices', bbox_inches='tight')


fig = plt.figure(figsize=(8, 8))
plt.boxplot(FEs)
plt.title('FEs by % of imputation')
plt.ylabel('free energy')
plt.xticks(range(0,10))
fig.savefig('nrgs_bp', bbox_inches='tight')
    
